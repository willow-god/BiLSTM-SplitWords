{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(BiLSTM_Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.bilstm1 = nn.LSTM(embedding_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "        self.bilstm2 = nn.LSTM(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bilstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.bilstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_Model(4666, 128, 64)\n",
    "max_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_Model(\n",
       "  (embedding): Embedding(4666, 128)\n",
       "  (bilstm1): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "  (dropout1): Dropout(p=0.6, inplace=False)\n",
       "  (bilstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "  (dropout2): Dropout(p=0.6, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model/BiLSTM_model.pkl'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14978\n",
      "14822\n"
     ]
    }
   ],
   "source": [
    "# 加载测试数据test_data.txt\n",
    "with open('data/test_data.txt', 'r', encoding='utf-8') as f:\n",
    "    test_data = f.read()\n",
    "\n",
    "# 将读取到的文本按照标点符号和换行符进行切分，得到一个列表\n",
    "test_data = re.split(r\"[，。！？、（）—《》…；“”\\n]\",test_data)\n",
    "\n",
    "# 去掉列表中的空字符串及空格\n",
    "test_data = [line.strip() for line in test_data if line.strip()]\n",
    "\n",
    "# 去掉每个句子中的空格\n",
    "test_data = [line.replace(\" \",\"\") for line in test_data]\n",
    "\n",
    "# 去掉所有长度大于max_len的句子之前\n",
    "print(len(test_data))\n",
    "    \n",
    "# 去掉所有长度大于max_len的句子\n",
    "test_data = [line for line in test_data if len(line)<=max_len]\n",
    "\n",
    "# 去掉所有长度小于max_len的句子之后\n",
    "print(len(test_data))\n",
    "\n",
    "# 保存处理后的测试数据\n",
    "with open('data/generate_pkl/test_data.pkl', 'wb') as f:\n",
    "    pkl.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理前测试数据大小： 14822\n",
      "处理前测试结果大小： 14978\n",
      "处理后测试数据大小： 14822\n",
      "处理后测试结果大小： 14822\n",
      "测试数据： ['共同创造美好的新世纪', '二○○一年新年贺词', '二○○○年十二月三十一日', '附图片1张', '女士们']\n",
      "测试结果： ['BEBEBESSBENNNNNNNNNNNNNNNNNNNNNN', 'BMMMEBEBENNNNNNNNNNNNNNNNNNNNNNN', 'BMMMEBMEBMMENNNNNNNNNNNNNNNNNNNN', 'SBESSNNNNNNNNNNNNNNNNNNNNNNNNNNN', 'BESNNNNNNNNNNNNNNNNNNNNNNNNNNNNN']\n"
     ]
    }
   ],
   "source": [
    "# 加载测试数据标签test_result.txt\n",
    "with open('data/test_result.txt', 'r', encoding='utf-8') as f:\n",
    "    test_result = f.read()\n",
    "\n",
    "# 将读取到的文本按照标点符号和换行符进行切分，得到一个列表\n",
    "test_result = re.split(r\"[，。！？、（）—《》…；“”\\n]\",test_result)\n",
    "\n",
    "# 去掉列表中的空字符串及空格\n",
    "test_result = [line.strip() for line in test_result if line.strip()]\n",
    "\n",
    "# 去掉每个句子首尾的空格\n",
    "test_result = list(map(lambda x:x.strip(),test_result))\n",
    "\n",
    "print(\"处理前测试数据大小：\", len(test_data))\n",
    "print(\"处理前测试结果大小：\", len(test_result))\n",
    "\n",
    "# 将每个句子的标签转化为字母\n",
    "sum_list = []\n",
    "for i in test_result:\n",
    "    sum_ = ''\n",
    "    for j in i.split():  #以空格为分割，一个词一个词的提取\n",
    "        if len(j) == 1: #如果词的长度为1 ，就标记为S -single\n",
    "            sum_ += 'S'\n",
    "            continue\n",
    "        else:\n",
    "            sum_ += 'B' #如果长度不为1，标记为一个词的开始 begin\n",
    "            for k in range(1, len(j)):\n",
    "                if k == len(j) - 1: #如果是这个词的最后一个，就标记为end\n",
    "                    sum_ += 'E'\n",
    "                else:\n",
    "                    sum_ += 'M'  #其他情况就是middle\n",
    "    # 如果句子长度小于等于max_len，就用\"N\"填充\n",
    "    if len(sum_) <= max_len:\n",
    "        sum_ += \"N\"*(max_len-len(sum_))\n",
    "        sum_list.append(sum_)\n",
    "\n",
    "print(\"处理后测试数据大小：\", len(test_data))\n",
    "print(\"处理后测试结果大小：\", len(sum_list))\n",
    "\n",
    "# 打印测试数据和测试结果\n",
    "print(\"测试数据：\", test_data[:5])\n",
    "print(\"测试结果：\", sum_list[:5])\n",
    "\n",
    "# 保存处理后的测试结果\n",
    "with open('data/generate_pkl/test_result.pkl', 'wb') as f:\n",
    "    pkl.dump(sum_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210, 62, 330, 332, 115, 113, 1, 33, 183, 378]\n",
      "14822\n",
      "[184, 185, 358, 419, 1046]\n",
      "219\n",
      "14822\n",
      "[139, 178, 42, 31, 6, 173, 106, 662, 249, 160, 238, 35, 1814, 1814, 0, 1739, 403, 136]\n",
      "[62, 274, 175, 249, 722, 722, 0, 722, 403, 136]\n",
      "[392, 364, 1133, 293, 77, 160, 0, 0, 0]\n",
      "[1765, 561, 561, 561, 12, 722, 1765, 75, 2135, 722, 40, 1765, 2135, 49, 722, 1765, 81, 4, 139, 178, 916, 53, 516, 247, 679, 38, 1, 986, 986, 947, 1941, 0]\n",
      "[531, 34, 235, 253, 990, 710, 1081, 0, 332, 567]\n",
      "14603\n",
      "14603\n"
     ]
    }
   ],
   "source": [
    "# 加载处理后的测试数据\n",
    "with open('data/generate_pkl/test_data.pkl', 'rb') as f:\n",
    "    test_data = pkl.load(f)\n",
    "\n",
    "# 加载处理后的测试结果\n",
    "with open('data/generate_pkl/test_result.pkl', 'rb') as f:\n",
    "    test_result = pkl.load(f)\n",
    "\n",
    "# 加载词典\n",
    "with open('data/generate_pkl/vocab.pkl', 'rb') as f:\n",
    "    word2id = pkl.load(f)\n",
    "\n",
    "# 将测试数据转换为id表示\n",
    "test_data_id = [[word2id[word] if word in word2id else 0 for word in line] for line in test_data]\n",
    "print(test_data_id[0])\n",
    "print(len(test_data_id))\n",
    "\n",
    "# 找到含有0的句子所对应的索引\n",
    "index = []\n",
    "for i in range(len(test_data_id)):\n",
    "    if 0 in test_data_id[i]:\n",
    "        index.append(i)\n",
    "print(index[:5])\n",
    "print(len(index))\n",
    "print(len(test_data_id))\n",
    "# 展示索引前5个对应的句子\n",
    "for i in range(5):\n",
    "    print(test_data_id[index[i]])\n",
    "\n",
    "# 去掉索引中对应的句子及其对应的标签\n",
    "test_data_id = [test_data_id[i] for i in range(len(test_data_id)) if i not in index]\n",
    "test_result = [test_result[i] for i in range(len(test_result)) if i not in index]\n",
    "\n",
    "print(len(test_data_id))\n",
    "print(len(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210, 62, 330, 332, 115, 113, 1, 33, 183, 378, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 2, 0, 2, 0, 2, 3, 3, 0, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "target_dict = {'B': 0,\n",
    "               'M': 1,\n",
    "               'E': 2,\n",
    "               'S': 3,\n",
    "               'N': 4}\n",
    "\n",
    "# 将测试数据补全为max_len长度\n",
    "test_data_id = [line + [0]*(max_len-len(line)) for line in test_data_id]\n",
    "print(test_data_id[0])\n",
    "\n",
    "# 将测试结果转换为id表示\n",
    "test_result_id = [[target_dict[word] for word in line] for line in test_result]\n",
    "print(test_result_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14603, 32])\n",
      "torch.Size([14603, 32])\n",
      "torch.Size([14603, 32, 5])\n"
     ]
    }
   ],
   "source": [
    "# 将测试数据和测试结果转换为tensor\n",
    "test_data_tensor = torch.tensor(test_data_id)\n",
    "test_result_tensor = torch.tensor(test_result_id)\n",
    "\n",
    "print(test_data_tensor.shape)\n",
    "print(test_result_tensor.shape)\n",
    "\n",
    "# 输入模型进行预测\n",
    "output = model(test_data_tensor)\n",
    "print(output.shape)\n",
    "\n",
    "# 将预测结果转换为numpy数组\n",
    "output = output.detach().numpy()\n",
    "\n",
    "# 将预测结果转换为标签\n",
    "output = np.argmax(output, axis=2)\n",
    "# print(output[0])\n",
    "\n",
    "# 将预测结果转换为字母\n",
    "output = [[list(target_dict.keys())[list(target_dict.values()).index(word)] for word in line] for line in output]\n",
    "# print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果： ['B', 'E', 'B', 'E', 'B', 'E', 'S', 'S', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "真实结果： BEBEBESSBENNNNNNNNNNNNNNNNNNNNNN\n"
     ]
    }
   ],
   "source": [
    "# 对比预测结果和真实结果\n",
    "print(\"预测结果：\", output[0])\n",
    "print(\"真实结果：\", test_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果： BEBEBESSBENNNNNNNNNNNNNNNNNNNNNN\n",
      "真实结果： BEBEBESSBENNNNNNNNNNNNNNNNNNNNNN\n"
     ]
    }
   ],
   "source": [
    "# 处理output\n",
    "output = [''.join(line) for line in output]\n",
    "print(\"预测结果：\", output[0])\n",
    "print(\"真实结果：\", test_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果： BEBEBESSBE\n",
      "真实结果： BEBEBESSBE\n"
     ]
    }
   ],
   "source": [
    "# 去除output和test_result中的\"N\"\n",
    "output = [line.replace(\"N\", \"\") for line in output]\n",
    "test_result = [line.replace(\"N\", \"\") for line in test_result]\n",
    "print(\"预测结果：\", output[0])\n",
    "print(\"真实结果：\", test_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8803521354616048\n",
      "召回率： 0.8803521354616048\n",
      "F1值： 0.8803521354616048\n"
     ]
    }
   ],
   "source": [
    "# 遍历二者中的每一行的每一个字母，计算预测结果和真实结果的准确率\n",
    "acc = 0\n",
    "for i in range(len(output)):\n",
    "    for j in range(len(output[i])):\n",
    "        if output[i][j] == test_result[i][j]:\n",
    "            acc += 1\n",
    "print(\"准确率：\", acc/sum([len(line) for line in test_result]))\n",
    "print(\"召回率：\", acc/sum([len(line) for line in output]))\n",
    "print(\"F1值：\", 2*acc/(sum([len(line) for line in test_result])+sum([len(line) for line in output])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
