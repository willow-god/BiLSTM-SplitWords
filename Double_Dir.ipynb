{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# -------------------------------------------------------------------- #\n",
    "#                   文件作用:使用正向最大匹配实现汉字分词                 #\n",
    "#                              作者:柳清扬                              #\n",
    "#                          时间:2023-09-27-09:25                       #\n",
    "# -------------------------------------------------------------------- #\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary_data[:10]: ['阿·朗', '阿·佩索尔', '阿巴斯', '阿巴斯·基阿鲁斯达米', '阿坝']\n"
     ]
    }
   ],
   "source": [
    "with open('data/dictionary.txt', 'r', encoding='utf-8') as dictionary_file:\n",
    "    dictionary_data = dictionary_file.read().split()\n",
    "print('dictionary_data[:10]:', list(dictionary_data)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义正向最大匹配分词函数\n",
    "def forward_max_match(text):\n",
    "    tokens = []\n",
    "    text_len = len(text)\n",
    "    max_word_len = max(len(word) for word in dictionary_data)\n",
    "\n",
    "    i = 0\n",
    "    while i < text_len:\n",
    "        matched = False\n",
    "        for j in range(max_word_len, 0, -1):\n",
    "            if i + j <= text_len:\n",
    "                word = text[i:i + j]\n",
    "                if word in dictionary_data:\n",
    "                    tokens.append(word)\n",
    "                    i += j\n",
    "                    matched = True\n",
    "                    break\n",
    "        if not matched:\n",
    "            tokens.append(text[i])\n",
    "            i += 1\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data[:10]: 共同创造美好的新世纪——二○○一年新年贺词\n"
     ]
    }
   ],
   "source": [
    "# 读取测试数据和测试结果\n",
    "with open('data/test_data.txt', 'r', encoding='utf-8') as test_data_file:\n",
    "    test_data = test_data_file.read().split()\n",
    "print('test_data[:10]:', list(test_data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['共同', '创造', '美好', '的', '新', '世纪', '——', '二○○一年', '新年', '贺词']\n"
     ]
    }
   ],
   "source": [
    "# 打开文件并读取内容\n",
    "with open('data/test_result.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 创建一个二维数组来存储数据\n",
    "test_result = []\n",
    "\n",
    "# 循环处理每行文本\n",
    "for line in lines:\n",
    "    # 使用空格分割每行的单词，并去除首尾空白字符\n",
    "    words = line.strip().split()\n",
    "    # 将单词数组添加到二维数组中\n",
    "    test_result.append(words)\n",
    "\n",
    "# 打印二维数组\n",
    "print(test_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据：\n",
      "共同创造美好的新世纪——二○○一年新年贺词\n",
      "\n",
      "分词结果：\n",
      "['共同', '创造', '美好', '的', '新', '世纪', '—', '—', '二', '○', '○', '一', '年', '新年', '贺词']\n",
      "\n",
      "正确结果：\n",
      "['共同', '创造', '美好', '的', '新', '世纪', '——', '二○○一年', '新年', '贺词']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_text = test_data[0]\n",
    "result_text = test_result[0]\n",
    "segmented_text =forward_max_match(test_text)\n",
    "print(f\"测试数据：\\n{test_text}\\n\")\n",
    "print(f\"分词结果：\\n{segmented_text}\\n\")\n",
    "print(f\"正确结果：\\n{result_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确分词数量：6\n",
      "总分词数量：10\n",
      "准确率：60.00%\n"
     ]
    }
   ],
   "source": [
    "# 计算匹配的分词数量\n",
    "correct_tokens = sum(1 for seg, cor in zip(segmented_text, result_text) if seg == cor)\n",
    "\n",
    "# 计算总分词数量\n",
    "total_tokens = len(result_text)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = correct_tokens / total_tokens\n",
    "\n",
    "print(f\"正确分词数量：{correct_tokens}\")\n",
    "print(f\"总分词数量：{total_tokens}\")\n",
    "print(f\"准确率：{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取此词语前面所有词语的长度之和\n",
    "def get_word_location(text, index):\n",
    "    locations = 0\n",
    "    if index == 0:\n",
    "        locations = 0\n",
    "    else:\n",
    "        for i in range(index):\n",
    "            locations += len(text[i])\n",
    "    return locations\n",
    "\n",
    "# 获取匹配此词语的所有位置\n",
    "def find_same_word_locations(text, word):\n",
    "    locations = []\n",
    "    # print(len(text))\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == word:\n",
    "            locations.append(i)\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# 测试两个函数\n",
    "segmented_text = ['共同', '创造', '美好', '的', '新', '世纪', '—', '—', '二', '○', '○', '一', '年', '新年', '贺词']\n",
    "result_data_line = ['共同', '创造', '美好', '的', '新', '世纪', '——', '二○○一', '年', '新', '年', '贺词']\n",
    "\n",
    "locations = find_same_word_locations(result_data_line, '新')\n",
    "for location in locations:\n",
    "    print(location)\n",
    "    print(get_word_location(result_data_line, location))\n",
    "    print(get_word_location(segmented_text, 4))\n",
    "    if get_word_location(result_data_line, location) == get_word_location(segmented_text, 4):\n",
    "        print(\"yes\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词计算进度：100/100\t准确率：0.8811671087533156\t\n",
      "正确分词数量：4983\n",
      "总分词数量：5655\n",
      "正确结果的词语总数：5414\n",
      "准确率：88.12%\n",
      "召回率：92.04%\n",
      "F1值：90.04%\n"
     ]
    }
   ],
   "source": [
    "# 准确率,召回率, F1值\n",
    "自己分的词语总数 = 0\n",
    "正确结果的词语总数 = 0\n",
    "正确的词语总数 = 0\n",
    "\n",
    "data = test_data[:100]\n",
    "# print('data[:10]:', list(data)[:5])\n",
    "\n",
    "# 循环处理每行文本\n",
    "for i in range(len(data)):\n",
    "\n",
    "    # 获取测试数据和测试结果\n",
    "    test_data_line = data[i]\n",
    "    result_data_line = test_result[i]\n",
    "\n",
    "    # 使用正向最大匹配算法分词\n",
    "    segmented_text = forward_max_match(test_data_line)\n",
    "\n",
    "    # 计算匹配的分词数量\n",
    "    自己分的词语总数 += len(segmented_text)\n",
    "    正确结果的词语总数 += len(result_data_line)\n",
    "\n",
    "    j = -1\n",
    "    # 计算正确的分词数量\n",
    "    for seg_word in segmented_text:\n",
    "        j += 1\n",
    "        if seg_word in result_data_line:\n",
    "            # 如果分词结果在正确结果中,则，查找所有匹配的位置并append到locations中\n",
    "            locations = find_same_word_locations(result_data_line, seg_word)\n",
    "            # 遍历locations中的每个位置，如果分词结果在正确结果中，则正确的词语总数加1\n",
    "            for loc in locations:\n",
    "                # 计算对比两个在字符串中的位置是否相同\n",
    "                if get_word_location(segmented_text, j) == get_word_location(result_data_line, loc):\n",
    "                    # 如果相同，直接加1\n",
    "                    正确的词语总数 += 1\n",
    "    \n",
    "    # 查看分词计算进度\n",
    "    print(f\"分词计算进度：{i + 1}/{len(data)}\\t准确率：{正确的词语总数 / 自己分的词语总数}\\t\", end='\\r')\n",
    "\n",
    "\n",
    "# 计算准确率\n",
    "准确率 = 正确的词语总数 / 自己分的词语总数\n",
    "召回率 = 正确的词语总数 / 正确结果的词语总数\n",
    "F1值 = 2 * 准确率 * 召回率 / (准确率 + 召回率)\n",
    "\n",
    "print(f\"\\n正确分词数量：{正确的词语总数}\")\n",
    "print(f\"总分词数量：{自己分的词语总数}\")\n",
    "print(f\"正确结果的词语总数：{正确结果的词语总数}\")\n",
    "\n",
    "print(f\"准确率：{准确率:.2%}\")\n",
    "print(f\"召回率：{召回率:.2%}\")\n",
    "print(f\"F1值：{F1值:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
